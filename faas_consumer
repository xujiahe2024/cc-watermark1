import base64
import json
from urllib.parse import unquote
from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips
import os
from google.cloud import firestore
from google.cloud import storage

import tempfile

output_dir = os.path.abspath('./output')


tmpdir = tempfile.gettempdir()



project_id = "watermarking-424614"
topic_id = "image-watermark"


Storage = storage.Client()
database = firestore.Client()

#tmpdir = os.path.abspath('./output')

    

def process_chunk(job_id, video_url, watermark_path, start, end, current_chunk, total_chunks):
        global Storage
        global database
        #print(f"Processing chunk {current_chunk} of {total_chunks} for job {job_id}")
        database = firestore.Client()
        job_ref = database.collection('job').document(job_id)
        
        video_path = f'{tmpdir}/{job_id}_video_{current_chunk}.webm'
        
        if not os.path.exists(tmpdir):
            os.makedirs(tmpdir)
        
        right_video_url = f'videos/{job_id}_{current_chunk}.webm'
        
        if not os.path.exists(video_path):
            blob = Storage.bucket('ccmarkbucket').blob(right_video_url)
            blob.download_to_filename(video_path)
            
            
        watermark_path = os.path.join(tmpdir, f'{job_id}_watermark.png')
        if not os.path.exists(watermark_path):
            blob = Storage.bucket('ccmarkbucket').blob(f'watermarks/{job_id}.png')
            blob.download_to_filename(watermark_path)
            
        #print(f"Downloaded video for job {job_id}")
        
        video = VideoFileClip(video_path)

        #video.duration = 10
        #video = VideoFileClip(video_path).subclip(start, end)
        watermark = ImageClip(watermark_path).set_duration(video.duration)
        watermark = watermark.resize(height=50).margin(right=8, bottom=8, opacity=0).set_position(("right", "bottom"))

        processed = CompositeVideoClip([video, watermark])
        
        os.remove(video_path)
        os.remove(watermark_path)
        
        chunk_path = f'{tmpdir}/{job_id}_final_chunk{current_chunk}.webm'
        #tmpfilePath = f'{tmpdir}/{job_id}_final_chunk_{current_chunk}_temp_audiofile_path'
        processed.write_videofile(chunk_path, temp_audiofile_path = tmpdir, logger = None)
        
        print(f"Processed chunk {current_chunk} of {total_chunks} for job {job_id}")

        bucket = Storage.bucket('ccmarkbucket')
        blob = bucket.blob(f'{output_dir}/{job_id}_final_chunk{current_chunk}.webm')
        blob.upload_from_filename(chunk_path)
        
        #delete chunk file
        os.remove(chunk_path)

        #print(f"Uploaded chunk {current_chunk} of {total_chunks} for job {job_id}")
        job_data = job_ref.get().to_dict()
        #print(f"Job data1: {job_data}")
        
        job_ref.update({'completed_chunks': firestore.Increment(1)})
        job_ref.set({f'task_{current_chunk}':"done"}, merge=True)

        job_data = job_ref.get().to_dict()
        #print(f"Job data2: {job_data}")
        if job_data['completed_chunks'] >= job_data['total_chunks']:
            print(f"All chunks processed for job {job_id}")
            #merge_chunks(job_id)
            #job_ref.update({'status': 'completed', 'progress': 100})



def merge_chunks(job_id):
    database = firestore.Client()
    job_ref = database.collection('job').document(job_id)
    job_data = job_ref.get().to_dict()
    #print(f"Job data3: {job_data}")
    chunks_path = [f'{tmpdir}/{job_id}_final_chunk{current_chunk}.webm' for current_chunk in range(job_data['total_chunks'])]
    #print(f"chunks_path: {chunks_path}")
    clips = [VideoFileClip(chunk) for chunk in chunks_path]
    final_clip = concatenate_videoclips(clips)
    #tmpfilePath = f'{tmpdir}/{job_id}_final_temp_audiofile_path'
    final_clip.write_videofile(f'{tmpdir}/final_{job_id}.mp4', temp_audiofile_path = tmpdir, logger = None)
    final_result_path = f'{tmpdir}/final_{job_id}.mp4'

    bucket = Storage.bucket('ccmarkbucket')
    final_blob = bucket.blob(f'{tmpdir}/{job_id}_final.mp4')
    final_blob.upload_from_filename(final_result_path)
    
    os.remove(final_result_path)
    
    print(f"Uploaded final result for job {job_id}")






def hello_pubsub(event, context):
    """Triggered from a message on a Cloud Pub/Sub topic.
    Args:
         event (dict): Event payload.
         context (google.cloud.functions.Context): Metadata for the event.
    """
    try:        
                pubsub_message = base64.b64decode(event['data']).decode('utf-8')
                #print(f"Received message : {pubsub_message}")
                pubsub_message = json.loads(pubsub_message)

                process_chunk(pubsub_message['job_id'], "", pubsub_message['watermark_path'], pubsub_message['start'], pubsub_message['end'], pubsub_message['chunk_num'], pubsub_message['total_chunks'])
    except Exception as e:
                print(f"An error occurred while processing message: {e}")